{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2035fe7-2214-4576-8479-2332e84161f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/1014936/ipykernel_2816675/2867124097.py:7: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#NOTE: The code below is configured to make running the code possible in Pace-ICE ondemand. You should either change the lines below to reflect your virtual env or comment them out.\n",
    "import sys\n",
    "sys.executable = 'miniconda3/envs/DRL/bin/python3.10'\n",
    "sys.path += ['/home/hice1/jwessell6/DRL/VLMAgent/Gym-Snake', '/home/hice1/jwessell6/miniconda3/envs/DRL/lib/python3.10', \n",
    "    '/home/hice1/jwessell6/miniconda3/envs/DRL/lib/python3.10/site-packages', '/home/hice1/jwessell6/miniconda3/envs/DRL/lib/python3.10/lib-dynload', '/home/hice1/jwessell6/.local/bin']\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "#from transformers import AutoProcessor, AutoModelForCausalLM, LlavaOnevisionForConditionalGeneration, BitsAndBytesConfig\n",
    "import pickle\n",
    "import argparse\n",
    "import gym\n",
    " \n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gym_snake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cafc377-f195-4ca3-8d17-ebcb1823d85a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" pip install llama-cpp-python==0.2.45 --force-reinstall --no-cache-dir\n",
    "#!wget -O ~/scratch/huggingface/ggml-model-q4_0.gguf https://huggingface.co/remyxai/SpaceLLaVA/resolve/main/ggml-model-q4_0.gguf?download=true\n",
    "#!wget -O ~/scratch/huggingface/mmproj-model-f16.gguf https://huggingface.co/remyxai/SpaceLLaVA/resolve/main/mmproj-model-f16.gguf?download=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4319a276-a315-47e9-8f1b-68a0430fbbe9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets  ggml-model-q4_0.gguf\thub  mmproj-model-f16.gguf\n"
     ]
    }
   ],
   "source": [
    "'''import sys\n",
    "sys.executable = 'miniconda3/envs/DRL/bin/python3.10'\n",
    "sys.path += ['/home/hice1/jwessell6/DRL/VLMAgent/Gym-Snake', '/home/hice1/jwessell6/miniconda3/envs/DRL/lib/python3.10', \n",
    "    '/home/hice1/jwessell6/miniconda3/envs/DRL/lib/python3.10/site-packages', '/home/hice1/jwessell6/miniconda3/envs/DRL/lib/python3.10/lib-dynload', '/home/hice1/jwessell6/.local/bin']\n",
    "'''\n",
    "import io\n",
    "import base64\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "from llama_cpp import Llama\n",
    "from llama_cpp.llama_chat_format import Llava15ChatHandler\n",
    "#import gym\n",
    "#import matplotlib.pyplot as plt\n",
    "#from Gym_Snake import gym_snake\n",
    "def image_to_base64_data_uri(image_input):\n",
    "    # Check if the input is a file path (string)\n",
    "    if isinstance(image_input, str):\n",
    "        with open(image_input, \"rb\") as img_file:\n",
    "            base64_data = base64.b64encode(img_file.read()).decode('utf-8')\n",
    "\n",
    "    # Check if the input is a PIL Image\n",
    "    elif isinstance(image_input, Image.Image):\n",
    "        buffer = io.BytesIO()\n",
    "        image_input.save(buffer, format=\"PNG\")  # You can change the format if needed\n",
    "        base64_data = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported input type. Input must be a file path or a PIL.Image.Image instance.\")\n",
    "\n",
    "    return f\"data:image/png;base64,{base64_data}\"\n",
    "\n",
    "mmproj=\"../../scratch/huggingface/ggml-model-q4_0.gguf\"\n",
    "model_path=\"../../scratch/huggingface/mmproj-model-f16.gguf\"\n",
    "chat_handler = Llava15ChatHandler(clip_model_path=mmproj, verbose=True)\n",
    "spacellava = Llama(model_path=model_path, chat_handler=chat_handler, n_ctx=2048, logits_all=True, n_gpu_layers = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a5a53d2-eefb-4baa-91db-de580768c56b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Converting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path with a SentencePiece tokenizer.model file.Currently available slow->fast convertors: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:1496\u001b[0m, in \u001b[0;36mTikTokenConverter.extract_vocab_merges_from_model\u001b[0;34m(self, tiktoken_url)\u001b[0m\n\u001b[1;32m   1495\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1496\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtiktoken\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_tiktoken_bpe\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tiktoken'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:1636\u001b[0m, in \u001b[0;36mconvert_slow_tokenizer\u001b[0;34m(transformer_tokenizer, from_tiktoken)\u001b[0m\n\u001b[1;32m   1632\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting from Tiktoken\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTikTokenConverter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformer_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1635\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformer_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madditional_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1637\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:1533\u001b[0m, in \u001b[0;36mTikTokenConverter.converted\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconverted\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tokenizer:\n\u001b[0;32m-> 1533\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1534\u001b[0m     tokenizer\u001b[38;5;241m.\u001b[39mpre_tokenizer \u001b[38;5;241m=\u001b[39m pre_tokenizers\u001b[38;5;241m.\u001b[39mSequence(\n\u001b[1;32m   1535\u001b[0m         [\n\u001b[1;32m   1536\u001b[0m             pre_tokenizers\u001b[38;5;241m.\u001b[39mSplit(Regex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpattern), behavior\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124misolated\u001b[39m\u001b[38;5;124m\"\u001b[39m, invert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1537\u001b[0m             pre_tokenizers\u001b[38;5;241m.\u001b[39mByteLevel(add_prefix_space\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space, use_regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1538\u001b[0m         ]\n\u001b[1;32m   1539\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:1526\u001b[0m, in \u001b[0;36mTikTokenConverter.tokenizer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenizer\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1526\u001b[0m     vocab_scores, merges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_vocab_merges_from_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1527\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m Tokenizer(BPE(vocab_scores, merges, fuse_unk\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:1498\u001b[0m, in \u001b[0;36mTikTokenConverter.extract_vocab_merges_from_model\u001b[0;34m(self, tiktoken_url)\u001b[0m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m-> 1498\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tiktoken` is required to read a `tiktoken` file. Install it with \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install tiktoken`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1500\u001b[0m     )\n\u001b[1;32m   1502\u001b[0m bpe_ranks \u001b[38;5;241m=\u001b[39m load_tiktoken_bpe(tiktoken_url)\n",
      "\u001b[0;31mValueError\u001b[0m: `tiktoken` is required to read a `tiktoken` file. Install it with `pip install tiktoken`.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#model = LlavaOnevisionForConditionalGeneration.from_pretrained(\"llava-hf/llava-onevision-qwen2-7b-ov-hf\", torch_dtype=torch.float16, device_map=\"auto\")\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Load model directly\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Use a pipeline as a high-level helper\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m processor \u001b[38;5;241m=\u001b[39m \u001b[43mAutoProcessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mremyxai/SpaceLLaVA\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mremyxai/SpaceLLaVA\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/auto/processing_auto.py:328\u001b[0m, in \u001b[0;36mAutoProcessor.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m processor_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    325\u001b[0m         pretrained_model_name_or_path, trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    326\u001b[0m     )\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m processor_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprocessor_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# Last try: we use the PROCESSOR_MAPPING.\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m PROCESSOR_MAPPING:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/processing_utils.py:944\u001b[0m, in \u001b[0;36mProcessorMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    942\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m token\n\u001b[0;32m--> 944\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_arguments_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    945\u001b[0m processor_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_processor_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    947\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_args_and_dict(args, processor_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/processing_utils.py:990\u001b[0m, in \u001b[0;36mProcessorMixin._get_arguments_from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    988\u001b[0m         attribute_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(transformers_module, class_name)\n\u001b[0;32m--> 990\u001b[0m     args\u001b[38;5;241m.\u001b[39mappend(\u001b[43mattribute_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    991\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m args\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:920\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    918\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenizer class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokenizer_class_candidate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist or is not currently imported.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    919\u001b[0m         )\n\u001b[0;32m--> 920\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;66;03m# Otherwise we have to be creative.\u001b[39;00m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# if model is an encoder decoder, the encoder tokenizer class is used by default\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, EncoderDecoderConfig):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2213\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2210\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2211\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_vocab_files[file_id]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresolved_vocab_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2216\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2217\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2221\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2222\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_is_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2224\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2447\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2445\u001b[0m \u001b[38;5;66;03m# Instantiate the tokenizer.\u001b[39;00m\n\u001b[1;32m   2446\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2447\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2448\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m import_protobuf_decode_error():\n\u001b[1;32m   2449\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   2450\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to load tokenizer model from SPM, loading from TikToken will be attempted instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2451\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Google protobuf error: Tried to load SPM model with non-SPM vocab file).\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2452\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/llama/tokenization_llama_fast.py:157\u001b[0m, in \u001b[0;36mLlamaTokenizerFast.__init__\u001b[0;34m(self, vocab_file, tokenizer_file, clean_up_tokenization_spaces, unk_token, bos_token, eos_token, add_bos_token, add_eos_token, use_default_system_prompt, legacy, add_prefix_space, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_prefix_space \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_slow\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocab_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43munk_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munk_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbos_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbos_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43meos_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meos_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_bos_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_bos_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_eos_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_eos_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_default_system_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_default_system_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_prefix_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_prefix_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlegacy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlegacy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_bos_token \u001b[38;5;241m=\u001b[39m add_bos_token\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_eos_token \u001b[38;5;241m=\u001b[39m add_eos_token\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:138\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madditional_special_tokens \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madditional_special_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n\u001b[0;32m--> 138\u001b[0m     fast_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_slow_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_tiktoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m     slow_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:1638\u001b[0m, in \u001b[0;36mconvert_slow_tokenizer\u001b[0;34m(transformer_tokenizer, from_tiktoken)\u001b[0m\n\u001b[1;32m   1633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TikTokenConverter(\n\u001b[1;32m   1634\u001b[0m         vocab_file\u001b[38;5;241m=\u001b[39mtransformer_tokenizer\u001b[38;5;241m.\u001b[39mvocab_file,\n\u001b[1;32m   1635\u001b[0m         additional_special_tokens\u001b[38;5;241m=\u001b[39mtransformer_tokenizer\u001b[38;5;241m.\u001b[39madditional_special_tokens,\n\u001b[1;32m   1636\u001b[0m     )\u001b[38;5;241m.\u001b[39mconverted()\n\u001b[1;32m   1637\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m-> 1638\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1639\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1640\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith a SentencePiece tokenizer.model file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1641\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently available slow->fast convertors: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(SLOW_TO_FAST_CONVERTERS\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1642\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Converting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path with a SentencePiece tokenizer.model file.Currently available slow->fast convertors: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']"
     ]
    }
   ],
   "source": [
    "#model = LlavaOnevisionForConditionalGeneration.from_pretrained(\"llava-hf/llava-onevision-qwen2-7b-ov-hf\", torch_dtype=torch.float16, device_map=\"auto\")\n",
    "# Load model directly\n",
    "# Use a pipeline as a high-level helper\n",
    "processor = AutoProcessor.from_pretrained(\"remyxai/SpaceLLaVA\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"remyxai/SpaceLLaVA\")\n",
    "model.eval()\n",
    "    #print(model.device)\n",
    "#processor = AutoProcessor.from_pretrained(\"llava-hf/llava-onevision-qwen2-7b-ov-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8462766-8d6d-4194-81fd-4a4525d002df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = gym.make('snake-v0')\n",
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01c01c06-c08d-4856-b433-05e688a00a29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "In the game of Snake, the objective is to control a snake that grows as it eats food items, such as cubes, while avoiding the edges of the playing field and its own body. The snake's movement is determined by the direction it is facing, and it will continue in that direction unless it is told to change.\n",
      "\n",
      "In the image provided, the snake's head is red and its body is black. The blue cube is located to the left of the snake's head, slightly above it. To eat the blue cube, the snake should move in the direction it is currently facing, which appears to be towards the left side of the image. This is because the snake's head is already aligned with the cube, and moving in the same direction would allow the snake to consume the cube without changing its direction.\n",
      "\n",
      "If the snake were to change direction to try to reach the cube, it would either have to turn around or turn to the right, which would not align the snake's head with the cube. Therefore, the most efficient and straightforward move for the snake to eat the blue cube is to continue moving in the direction it is currently facing, which is to the left.\n",
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import utils\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "image = state\n",
    "plt.imshow(image)\n",
    "images = [image]#[eg_img, image]\n",
    "chat = utils.make_conversation(0, \"snake-v0\",\"\") #eg_txt)\n",
    "prompt = processor.apply_chat_template(chat, add_generation_prompt=True)\n",
    "inputs = processor(images=images, text=prompt, return_tensors=\"pt\").to(\"cuda:0\", torch.float16)\n",
    "output = model.generate(**inputs, max_new_tokens=500)\n",
    "instruction = processor.decode(output[0][len(inputs['input_ids'][0]):], skip_special_tokens=True)\n",
    "print(instruction)\n",
    "action = utils.decode(\"snake-v0\", instruction[len(inputs) : ].lower())\n",
    "print(action)\n",
    "state, reward, done, trunc = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cd37e2e-9128-4485-a4b5-c2b1a53dc97e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1627\n",
      "right\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#new_\n",
    "#print(new_state)\n",
    "#print(reward)\n",
    "#print(done)\n",
    "#print(trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d10e8e6-217d-4005-aa3e-79ec1e4eadad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DRL python3.10",
   "language": "python",
   "name": "drl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
